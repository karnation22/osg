{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\Anuja Mitra\\\\Desktop\\\\OSG-Engage'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-0d0149abbaa1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\Anuja Mitra\\Desktop\\OSG-Engage'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'180515.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\Anuja Mitra\\\\Desktop\\\\OSG-Engage'"
     ]
    }
   ],
   "source": [
    "os.chdir(r'C:\\Users\\Anuja Mitra\\Desktop\\OSG-Engage')\n",
    "data=pd.read_excel('180515.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engage_word_frequency(data,n):\n",
    "    import nltk\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    text = data['SQ02'].dropna(how='any')\n",
    "    \n",
    "    def remove_unwanted_words(text):\n",
    "        from nltk.corpus import wordnet as wn\n",
    "        from nltk import pos_tag\n",
    "        import nltk\n",
    "        sentence = text\n",
    "        sentence = nltk.word_tokenize(sentence)\n",
    "        sent = pos_tag(sentence)\n",
    "        list_v=['PRP','PRP$','UH','WDT','WP','WP$','WRB','TO','VBZ','IN']\n",
    "        wordlist=[s for s in sent if s[1] not in list_v]\n",
    "        wordlist=pd.DataFrame(wordlist,columns=['word','type'])\n",
    "        words = wordlist['word']\n",
    "        return words\n",
    "    \n",
    "    \n",
    "    def wordFreq(data):\n",
    "        from nltk.tokenize import word_tokenize\n",
    "        from nltk.corpus import stopwords as sw\n",
    "        word_Dict = {}\n",
    "        for i in data:\n",
    "            #listOfWords = remove_punctuation(str(i))\n",
    "        #listOfWords = word_tokenize(str(i))\n",
    "            listOfWords=remove_unwanted_words(str(i)).tolist()\n",
    "            for j in listOfWords:\n",
    "                if (j in word_Dict):\n",
    "                    word_Dict[j] += 1\n",
    "                else:\n",
    "                    word_Dict[j] = 1\n",
    "        Keys = []\n",
    "        Values = []\n",
    "        Custom = []\n",
    "        stop_words = set(sw.words(\"english\"))\n",
    "        Custom.append(\"product\")\n",
    "        Custom.append(\"The\")\n",
    "        Custom.append(\"I\")\n",
    "        for i in word_Dict:\n",
    "            if (i not in stop_words and i.isalpha() and i not in Custom):\n",
    "                Keys.append(i)\n",
    "                Values.append(word_Dict[i])\n",
    "        Word_Stat = {'Word': Keys, 'Count': Values}\n",
    "        Word_Stat = pd.DataFrame(Word_Stat)\n",
    "        Word_Stat = Word_Stat.sort_values(['Count'], ascending=False) \n",
    "        return (Word_Stat[1:n])\n",
    "\n",
    "    data = text    \n",
    "    Final_result = wordFreq(data)\n",
    "    return Final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = engage_word_frequency(data,50).set_index('Word')['Count'].to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"taste\":5,\"service\":4,\"better\":3,\"food\":3,\"gud\":2,\"visits\":2,\"liked\":2,\"Pizza\":2,\"quality\":2,\"However\":2,\"junk\":2,\"base\":2,\"recommend\":2,\"eat\":2,\"Dominos\":2,\"would\":2,\"pizza\":2,\"deliver\":2,\"customer\":2,\"crust\":2,\"delivery\":2,\"bad\":2,\"options\":2,\"conveniently\":1,\"value\":1,\"feel\":1,\"Taste\":1,\"But\":1,\"enjoy\":1,\"kid\":1,\"deals\":1,\"friends\":1,\"experience\":1,\"rarely\":1,\"available\":1,\"flavors\":1,\"More\":1,\"price\":1,\"less\":1,\"quantity\":1,\"large\":1,\"Tasty\":1,\"Descent\":1,\"recent\":1,\"Low\":1,\"decent\":1,\"option\":1,\"wheat\":1,\"soft\":1}'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
